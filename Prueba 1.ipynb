{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b827876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoModelForCausalLM, AutoTokenizer, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec8b122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'Why is model conversion important?',\n",
    "    'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4adf287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.21171434223651886,\n",
       " 'start': 59,\n",
       " 'end': 84,\n",
       " 'answer': 'gives freedom to the user'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fea4767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4834faf9d940412db1eb3ad13260dfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989bf8700c724551b98d580038780270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3149e0486ff4b3a802ecbfb8e59d818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718a0114b0854edeaef1195f6cf4fd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835dd672ab484b9d82a897a2ec2cbd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60bb726e8c741828dd9c5a5c2f157c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I install tensorflow?\n",
      "Step 0: Go to https://github.com/tensorflow/tensorflow.git\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I install tensorflow?\n",
      "Step 0: Go to https://github.com/tensorflow/tensorflow.git\n",
      "Step 1: Run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I install tensorflow?\n",
      "Step 0: Go to https://github.com/tensorflow/tensorflow.git\n",
      "Step 1: Run\n",
      "Step 2: Install\n"
     ]
    }
   ],
   "source": [
    "# model names: \"gpt2-large\"/\"EleutherAI/gpt-neo-2.7B\" \n",
    "model_name = \"EleutherAI/gpt-neo-2.7B\" \n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "prompt = \"How do I install tensorflow?\"\n",
    "for i in range(20):\n",
    "    prompt = prompt + \"\\nStep \" + str(i) + \": \"\n",
    "    inputs = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    prompt_length = len(tokenizer.decode(inputs[0]))\n",
    "    outputs = model.generate(inputs, max_length=512, do_sample=True, top_p=0.95, top_k=60)\n",
    "    generated = tokenizer.decode(outputs[0])[prompt_length + 1 :]\n",
    "    stop_idx = generated.index('\\n') if '\\n' in generated else None\n",
    "    generated = generated[:stop_idx]\n",
    "    if (len(generated) == 0):\n",
    "        break\n",
    "    end_idx = generated.index('<|endoftext|>') if '<|endoftext|>' in generated else None\n",
    "    if (end_idx != None):\n",
    "        generated = generated[:end_idx]\n",
    "        prompt = prompt + generated\n",
    "        print(prompt)\n",
    "        break\n",
    "    prompt = prompt + generated\n",
    "    print(prompt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf155bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
